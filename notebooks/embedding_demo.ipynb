{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830e77f1",
   "metadata": {},
   "source": [
    "# üéµ Music Embeddings Extraction Demo\n",
    "\n",
    "**Created by Sergie Code - AI Tools for Musicians**\n",
    "\n",
    "This notebook demonstrates how to extract embeddings from audio files using state-of-the-art models like **OpenL3** and **AudioCLIP**. These embeddings form the foundation for:\n",
    "\n",
    "- üîç **Music Similarity Search**\n",
    "- üõ°Ô∏è **Copyright & Plagiarism Detection** \n",
    "- ü§ñ **AI Music Analysis Tools**\n",
    "- üìä **Music Recommendation Systems**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "1. How to extract embeddings from audio files\n",
    "2. Compare different embedding models\n",
    "3. Calculate audio similarity\n",
    "4. Visualize embeddings in 2D space\n",
    "5. Build a foundation for vector search systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22aa10",
   "metadata": {},
   "source": [
    "## 1. Project Setup and Dependencies\n",
    "\n",
    "First, let's verify our project structure and install any missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the src directory to Python path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"üìÅ Source path: {src_path}\")\n",
    "\n",
    "# Check project structure\n",
    "expected_files = [\n",
    "    'src/embeddings.py',\n",
    "    'src/utils.py', \n",
    "    'src/__init__.py',\n",
    "    'requirements.txt',\n",
    "    'README.md'\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Checking project structure:\")\n",
    "for file in expected_files:\n",
    "    file_path = os.path.join(project_root, file)\n",
    "    status = \"‚úÖ\" if os.path.exists(file_path) else \"‚ùå\"\n",
    "    print(f\"  {status} {file}\")\n",
    "\n",
    "# Create a data directory for sample audio files\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"\\nüìÇ Data directory ready: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have audio files to work with\n",
    "audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']\n",
    "audio_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in audio_extensions):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"üéµ Found {len(audio_files)} audio files in data directory:\")\n",
    "for i, audio_file in enumerate(audio_files[:5]):  # Show first 5\n",
    "    print(f\"  {i+1}. {os.path.basename(audio_file)}\")\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è No audio files found. To run this demo:\")\n",
    "    print(f\"   1. Add some audio files to: {data_dir}\")\n",
    "    print(\"   2. Or we'll create synthetic audio for demonstration\")\n",
    "    \n",
    "    # Create synthetic audio for demo\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "    \n",
    "    print(\"\\nüîß Creating synthetic demo audio...\")\n",
    "    sample_rate = 22050\n",
    "    duration = 5  # 5 seconds\n",
    "    \n",
    "    # Create different types of synthetic audio\n",
    "    synthetic_files = [\n",
    "        ('demo_sine_wave.wav', 'Sine wave at 440 Hz'),\n",
    "        ('demo_chirp.wav', 'Frequency sweep'),\n",
    "        ('demo_noise.wav', 'Pink noise')\n",
    "    ]\n",
    "    \n",
    "    for filename, description in synthetic_files:\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        if 'sine' in filename:\n",
    "            # Pure sine wave\n",
    "            t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "            audio = 0.3 * np.sin(2 * np.pi * 440 * t)  # 440 Hz (A4)\n",
    "            \n",
    "        elif 'chirp' in filename:\n",
    "            # Frequency sweep\n",
    "            t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "            freq = 200 + (2000 - 200) * t / duration  # 200 Hz to 2000 Hz\n",
    "            audio = 0.3 * np.sin(2 * np.pi * freq * t)\n",
    "            \n",
    "        elif 'noise' in filename:\n",
    "            # Pink noise\n",
    "            audio = np.random.normal(0, 0.1, int(sample_rate * duration))\n",
    "            \n",
    "        sf.write(filepath, audio, sample_rate)\n",
    "        audio_files.append(filepath)\n",
    "        print(f\"  ‚úÖ Created: {filename} ({description})\")\n",
    "\n",
    "print(f\"\\nüéµ Total audio files available: {len(audio_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd0c80",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all the libraries we need for audio processing and embedding extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8200fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display\n",
    "import warnings\n",
    "\n",
    "# Custom modules\n",
    "try:\n",
    "    from embeddings import AudioEmbeddingExtractor, compare_embeddings\n",
    "    from utils import load_audio, preprocess_audio, save_embeddings, load_embeddings, get_audio_info\n",
    "    print(\"‚úÖ Successfully imported custom modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing custom modules: {e}\")\n",
    "    print(\"   Make sure the src directory is in your Python path\")\n",
    "\n",
    "# Visualization libraries\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "    print(\"‚úÖ Scikit-learn available for visualizations\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Scikit-learn not available - install for visualizations\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nüöÄ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc15180",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Audio Files\n",
    "\n",
    "Let's load our audio files and explore their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first few audio files for our demo\n",
    "demo_files = audio_files[:3] if len(audio_files) >= 3 else audio_files\n",
    "\n",
    "print(f\"üéµ Working with {len(demo_files)} audio files:\")\n",
    "\n",
    "# Load and analyze each file\n",
    "audio_data = {}\n",
    "\n",
    "for i, filepath in enumerate(demo_files):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print(f\"\\nüìÅ File {i+1}: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Get file info\n",
    "        info = get_audio_info(filepath)\n",
    "        print(f\"   Duration: {info['duration_seconds']:.2f}s\")\n",
    "        print(f\"   Sample Rate: {info['sample_rate']} Hz\")\n",
    "        print(f\"   Channels: {info['channels']}\")\n",
    "        print(f\"   Format: {info['format']}\")\n",
    "        \n",
    "        # Load audio\n",
    "        audio, sr = load_audio(filepath, target_sr=22050)\n",
    "        \n",
    "        # Preprocess\n",
    "        processed_audio = preprocess_audio(audio, target_sr=sr, max_duration=10.0)\n",
    "        \n",
    "        # Store data\n",
    "        audio_data[filename] = {\n",
    "            'filepath': filepath,\n",
    "            'audio': processed_audio,\n",
    "            'sr': sr,\n",
    "            'info': info\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Processed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(audio_data)} audio files successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe14176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the audio waveforms\n",
    "fig, axes = plt.subplots(len(audio_data), 2, figsize=(15, 4*len(audio_data)))\n",
    "if len(audio_data) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, (filename, data) in enumerate(audio_data.items()):\n",
    "    audio = data['audio']\n",
    "    sr = data['sr']\n",
    "    \n",
    "    # Waveform\n",
    "    axes[i, 0].plot(np.linspace(0, len(audio)/sr, len(audio)), audio)\n",
    "    axes[i, 0].set_title(f'Waveform: {filename}')\n",
    "    axes[i, 0].set_xlabel('Time (s)')\n",
    "    axes[i, 0].set_ylabel('Amplitude')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    librosa.display.specshow(D, y_axis='hz', x_axis='time', sr=sr, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'Spectrogram: {filename}')\n",
    "    axes[i, 1].set_ylabel('Frequency (Hz)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display audio players\n",
    "print(\"üîä Audio Players:\")\n",
    "for filename, data in audio_data.items():\n",
    "    print(f\"\\nüéµ {filename}:\")\n",
    "    display(Audio(data['audio'], rate=data['sr']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31430c55",
   "metadata": {},
   "source": [
    "## 4. Extract Embeddings with OpenL3\n",
    "\n",
    "Now let's extract embeddings using the OpenL3 model, which is excellent for general audio analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenL3 extractor\n",
    "print(\"üîß Initializing OpenL3 extractor...\")\n",
    "\n",
    "try:\n",
    "    openl3_extractor = AudioEmbeddingExtractor(\n",
    "        model_name='openl3',\n",
    "        input_repr='mel256',\n",
    "        content_type='music',\n",
    "        embedding_size=6144\n",
    "    )\n",
    "    print(\"‚úÖ OpenL3 extractor initialized successfully\")\n",
    "    \n",
    "    # Get model info\n",
    "    model_info = openl3_extractor.get_embedding_info()\n",
    "    print(f\"\\nüìä Model Information:\")\n",
    "    print(f\"   Model: {model_info['model_description']}\")\n",
    "    print(f\"   Embedding dimension: {model_info['embedding_dimension']}\")\n",
    "    print(f\"   Data type: {model_info['embedding_dtype']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå OpenL3 not available: {e}\")\n",
    "    print(\"   Falling back to spectrogram-based embeddings...\")\n",
    "    \n",
    "    openl3_extractor = AudioEmbeddingExtractor(\n",
    "        model_name='spectrogram',\n",
    "        n_mels=128\n",
    "    )\n",
    "    model_info = openl3_extractor.get_embedding_info()\n",
    "    print(f\"\\nüìä Fallback Model Information:\")\n",
    "    print(f\"   Model: {model_info['model_description']}\")\n",
    "    print(f\"   Embedding dimension: {model_info['embedding_dimension']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e87abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for all audio files\n",
    "print(\"üéµ Extracting embeddings with OpenL3...\")\n",
    "\n",
    "openl3_embeddings = {}\n",
    "\n",
    "for filename, data in audio_data.items():\n",
    "    print(f\"\\nüîç Processing: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract embedding\n",
    "        embedding = openl3_extractor.extract_embeddings_from_array(\n",
    "            data['audio'], \n",
    "            data['sr']\n",
    "        )\n",
    "        \n",
    "        openl3_embeddings[filename] = embedding\n",
    "        \n",
    "        print(f\"   ‚úÖ Embedding shape: {embedding.shape}\")\n",
    "        print(f\"   üìä Stats: min={embedding.min():.3f}, max={embedding.max():.3f}, mean={embedding.mean():.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted embeddings for {len(openl3_embeddings)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba07581",
   "metadata": {},
   "source": [
    "## 5. Extract Embeddings with AudioCLIP\n",
    "\n",
    "Let's also try AudioCLIP, which provides multi-modal embeddings that can relate audio to text descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AudioCLIP extractor\n",
    "print(\"üîß Initializing AudioCLIP extractor...\")\n",
    "\n",
    "try:\n",
    "    audioclip_extractor = AudioEmbeddingExtractor(\n",
    "        model_name='audioclip',\n",
    "        model_name='microsoft/unispeech-large'\n",
    "    )\n",
    "    print(\"‚úÖ AudioCLIP extractor initialized successfully\")\n",
    "    \n",
    "    # Get model info\n",
    "    model_info_audioclip = audioclip_extractor.get_embedding_info()\n",
    "    print(f\"\\nüìä AudioCLIP Model Information:\")\n",
    "    print(f\"   Model: {model_info_audioclip['model_description']}\")\n",
    "    print(f\"   Embedding dimension: {model_info_audioclip['embedding_dimension']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå AudioCLIP not available: {e}\")\n",
    "    print(\"   Will use OpenL3 embeddings for comparison...\")\n",
    "    audioclip_extractor = None\n",
    "    model_info_audioclip = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd748c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract AudioCLIP embeddings if available\n",
    "audioclip_embeddings = {}\n",
    "\n",
    "if audioclip_extractor is not None:\n",
    "    print(\"üéµ Extracting embeddings with AudioCLIP...\")\n",
    "    \n",
    "    for filename, data in audio_data.items():\n",
    "        print(f\"\\nüîç Processing: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract embedding\n",
    "            embedding = audioclip_extractor.extract_embeddings_from_array(\n",
    "                data['audio'], \n",
    "                data['sr']\n",
    "            )\n",
    "            \n",
    "            audioclip_embeddings[filename] = embedding\n",
    "            \n",
    "            print(f\"   ‚úÖ Embedding shape: {embedding.shape}\")\n",
    "            print(f\"   üìä Stats: min={embedding.min():.3f}, max={embedding.max():.3f}, mean={embedding.mean():.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "            \n",
    "    print(f\"\\n‚úÖ Extracted AudioCLIP embeddings for {len(audioclip_embeddings)} files\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping AudioCLIP embeddings (not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e4340",
   "metadata": {},
   "source": [
    "## 6. Compare Different Embedding Models\n",
    "\n",
    "Let's compare the embeddings from different models and see how they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embedding characteristics\n",
    "print(\"üìä Embedding Model Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for filename in openl3_embeddings.keys():\n",
    "    openl3_emb = openl3_embeddings[filename]\n",
    "    \n",
    "    # OpenL3 stats\n",
    "    comparison_data.append({\n",
    "        'File': filename,\n",
    "        'Model': 'OpenL3',\n",
    "        'Dimensions': openl3_emb.shape[0],\n",
    "        'Min': openl3_emb.min(),\n",
    "        'Max': openl3_emb.max(),\n",
    "        'Mean': openl3_emb.mean(),\n",
    "        'Std': openl3_emb.std(),\n",
    "        'L2 Norm': np.linalg.norm(openl3_emb)\n",
    "    })\n",
    "    \n",
    "    # AudioCLIP stats (if available)\n",
    "    if filename in audioclip_embeddings:\n",
    "        audioclip_emb = audioclip_embeddings[filename]\n",
    "        comparison_data.append({\n",
    "            'File': filename,\n",
    "            'Model': 'AudioCLIP',\n",
    "            'Dimensions': audioclip_emb.shape[0],\n",
    "            'Min': audioclip_emb.min(),\n",
    "            'Max': audioclip_emb.max(),\n",
    "            'Mean': audioclip_emb.mean(),\n",
    "            'Std': audioclip_emb.std(),\n",
    "            'L2 Norm': np.linalg.norm(audioclip_emb)\n",
    "        })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüìã Embedding Statistics:\")\n",
    "display(df_comparison.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding distributions\n",
    "if len(openl3_embeddings) > 0:\n",
    "    n_files = len(openl3_embeddings)\n",
    "    fig, axes = plt.subplots(n_files, 2, figsize=(15, 4*n_files))\n",
    "    \n",
    "    if n_files == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, (filename, embedding) in enumerate(openl3_embeddings.items()):\n",
    "        # OpenL3 histogram\n",
    "        axes[i, 0].hist(embedding, bins=50, alpha=0.7, color='blue', label='OpenL3')\n",
    "        axes[i, 0].set_title(f'OpenL3 Distribution: {filename}')\n",
    "        axes[i, 0].set_xlabel('Embedding Value')\n",
    "        axes[i, 0].set_ylabel('Frequency')\n",
    "        axes[i, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Embedding values over dimensions\n",
    "        axes[i, 1].plot(embedding[:100], alpha=0.8, color='blue', label='OpenL3 (first 100 dims)')  # Show first 100 dimensions\n",
    "        \n",
    "        # Add AudioCLIP if available\n",
    "        if filename in audioclip_embeddings:\n",
    "            audioclip_emb = audioclip_embeddings[filename]\n",
    "            axes[i, 0].hist(audioclip_emb, bins=50, alpha=0.7, color='red', label='AudioCLIP')\n",
    "            axes[i, 1].plot(audioclip_emb[:100], alpha=0.8, color='red', label='AudioCLIP (first 100 dims)')\n",
    "        \n",
    "        axes[i, 0].legend()\n",
    "        axes[i, 1].legend()\n",
    "        axes[i, 1].set_title(f'Embedding Values: {filename}')\n",
    "        axes[i, 1].set_xlabel('Dimension')\n",
    "        axes[i, 1].set_ylabel('Value')\n",
    "        axes[i, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdff5e6",
   "metadata": {},
   "source": [
    "## 7. Save and Load Embeddings\n",
    "\n",
    "Let's save our embeddings to disk so we can reuse them later without re-computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d26fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings directory\n",
    "embeddings_dir = os.path.join(project_root, 'embeddings')\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving embeddings to: {embeddings_dir}\")\n",
    "\n",
    "# Save OpenL3 embeddings\n",
    "for filename, embedding in openl3_embeddings.items():\n",
    "    # Create metadata\n",
    "    metadata = {\n",
    "        'original_file': filename,\n",
    "        'model': 'OpenL3',\n",
    "        'model_config': {\n",
    "            'input_repr': 'mel256',\n",
    "            'content_type': 'music',\n",
    "            'embedding_size': embedding.shape[0]\n",
    "        },\n",
    "        'extraction_date': pd.Timestamp.now().isoformat(),\n",
    "        'embedding_shape': embedding.shape,\n",
    "        'embedding_stats': {\n",
    "            'mean': float(embedding.mean()),\n",
    "            'std': float(embedding.std()),\n",
    "            'min': float(embedding.min()),\n",
    "            'max': float(embedding.max())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save in different formats\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Pickle format (includes metadata)\n",
    "    pickle_path = os.path.join(embeddings_dir, f\"{base_name}_openl3.pkl\")\n",
    "    save_embeddings(embedding, pickle_path, metadata, format='pickle')\n",
    "    \n",
    "    # NumPy format\n",
    "    npy_path = os.path.join(embeddings_dir, f\"{base_name}_openl3.npy\")\n",
    "    save_embeddings(embedding, npy_path, metadata, format='npy')\n",
    "\n",
    "# Save AudioCLIP embeddings if available\n",
    "for filename, embedding in audioclip_embeddings.items():\n",
    "    metadata = {\n",
    "        'original_file': filename,\n",
    "        'model': 'AudioCLIP',\n",
    "        'extraction_date': pd.Timestamp.now().isoformat(),\n",
    "        'embedding_shape': embedding.shape,\n",
    "        'embedding_stats': {\n",
    "            'mean': float(embedding.mean()),\n",
    "            'std': float(embedding.std()),\n",
    "            'min': float(embedding.min()),\n",
    "            'max': float(embedding.max())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    pickle_path = os.path.join(embeddings_dir, f\"{base_name}_audioclip.pkl\")\n",
    "    save_embeddings(embedding, pickle_path, metadata, format='pickle')\n",
    "\n",
    "print(\"\\n‚úÖ Embeddings saved successfully!\")\n",
    "\n",
    "# List saved files\n",
    "saved_files = os.listdir(embeddings_dir)\n",
    "print(f\"\\nüìÅ Saved {len(saved_files)} embedding files:\")\n",
    "for file in sorted(saved_files):\n",
    "    print(f\"   üìÑ {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loading embeddings\n",
    "print(\"üîÑ Testing embedding loading...\")\n",
    "\n",
    "# Load one of the saved embeddings\n",
    "if saved_files:\n",
    "    test_file = os.path.join(embeddings_dir, saved_files[0])\n",
    "    loaded_embedding, loaded_metadata = load_embeddings(test_file)\n",
    "    \n",
    "    print(f\"\\nüìä Loaded embedding from: {saved_files[0]}\")\n",
    "    print(f\"   Shape: {loaded_embedding.shape}\")\n",
    "    print(f\"   Model: {loaded_metadata.get('model', 'Unknown')}\")\n",
    "    print(f\"   Original file: {loaded_metadata.get('original_file', 'Unknown')}\")\n",
    "    print(f\"   Extraction date: {loaded_metadata.get('extraction_date', 'Unknown')}\")\n",
    "    \n",
    "    # Verify it's the same as original\n",
    "    original_filename = loaded_metadata.get('original_file')\n",
    "    if original_filename in openl3_embeddings:\n",
    "        original_embedding = openl3_embeddings[original_filename]\n",
    "        if np.allclose(loaded_embedding, original_embedding):\n",
    "            print(\"   ‚úÖ Loaded embedding matches original!\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Loaded embedding differs from original\")\n",
    "            \n",
    "print(\"\\n‚úÖ Embedding save/load system working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8dc412",
   "metadata": {},
   "source": [
    "## 8. Visualize Embeddings with t-SNE\n",
    "\n",
    "Let's use dimensionality reduction to visualize our high-dimensional embeddings in 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03884ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Collect all embeddings\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_models = []\n",
    "    \n",
    "    # Add OpenL3 embeddings\n",
    "    for filename, embedding in openl3_embeddings.items():\n",
    "        all_embeddings.append(embedding)\n",
    "        all_labels.append(filename)\n",
    "        all_models.append('OpenL3')\n",
    "    \n",
    "    # Add AudioCLIP embeddings if available\n",
    "    for filename, embedding in audioclip_embeddings.items():\n",
    "        all_embeddings.append(embedding)\n",
    "        all_labels.append(filename)\n",
    "        all_models.append('AudioCLIP')\n",
    "    \n",
    "    if len(all_embeddings) > 1:\n",
    "        # Convert to matrix\n",
    "        embeddings_matrix = np.vstack(all_embeddings)\n",
    "        \n",
    "        print(f\"üìä Visualizing {len(all_embeddings)} embeddings\")\n",
    "        print(f\"   Embedding matrix shape: {embeddings_matrix.shape}\")\n",
    "        \n",
    "        # Apply PCA first to reduce dimensions (for t-SNE efficiency)\n",
    "        if embeddings_matrix.shape[1] > 50:\n",
    "            print(\"üîß Applying PCA preprocessing...\")\n",
    "            pca = PCA(n_components=50)\n",
    "            embeddings_pca = pca.fit_transform(embeddings_matrix)\n",
    "            print(f\"   PCA explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "        else:\n",
    "            embeddings_pca = embeddings_matrix\n",
    "        \n",
    "        # Apply t-SNE\n",
    "        print(\"üîß Applying t-SNE...\")\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(all_embeddings)-1))\n",
    "        embeddings_2d = tsne.fit_transform(embeddings_pca)\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot points colored by model\n",
    "        unique_models = list(set(all_models))\n",
    "        colors = plt.cm.Set1(np.linspace(0, 1, len(unique_models)))\n",
    "        \n",
    "        for model, color in zip(unique_models, colors):\n",
    "            mask = np.array(all_models) == model\n",
    "            plt.scatter(\n",
    "                embeddings_2d[mask, 0], \n",
    "                embeddings_2d[mask, 1],\n",
    "                c=[color], \n",
    "                label=model, \n",
    "                s=100, \n",
    "                alpha=0.7,\n",
    "                edgecolors='black',\n",
    "                linewidth=1\n",
    "            )\n",
    "        \n",
    "        # Add labels\n",
    "        for i, (x, y) in enumerate(embeddings_2d):\n",
    "            plt.annotate(\n",
    "                f\"{all_labels[i]}\\n({all_models[i]})\", \n",
    "                (x, y), \n",
    "                xytext=(5, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=8,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7)\n",
    "            )\n",
    "        \n",
    "        plt.title('Audio Embeddings Visualization (t-SNE)', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('t-SNE Component 1')\n",
    "        plt.ylabel('t-SNE Component 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text box with info\n",
    "        info_text = f\"Embeddings: {len(all_embeddings)}\\nOriginal dims: {embeddings_matrix.shape[1]}\\nPCA dims: {embeddings_pca.shape[1]}\"\n",
    "        plt.text(0.02, 0.98, info_text, transform=plt.gca().transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                verticalalignment='top', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ t-SNE visualization complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Need at least 2 embeddings for visualization\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ùå Scikit-learn not available for t-SNE visualization\")\n",
    "    print(\"   Install with: pip install scikit-learn\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde5520",
   "metadata": {},
   "source": [
    "## 9. Calculate Audio Similarity\n",
    "\n",
    "Now let's calculate similarity between different audio files using their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89952527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity matrices\n",
    "if len(openl3_embeddings) > 1:\n",
    "    print(\"üîç Calculating audio similarities...\")\n",
    "    \n",
    "    # Get file names and embeddings\n",
    "    filenames = list(openl3_embeddings.keys())\n",
    "    embeddings_list = [openl3_embeddings[f] for f in filenames]\n",
    "    \n",
    "    # Calculate similarity matrix using different methods\n",
    "    similarity_methods = ['cosine', 'euclidean', 'correlation']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(similarity_methods), figsize=(5*len(similarity_methods), 4))\n",
    "    if len(similarity_methods) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for method_idx, method in enumerate(similarity_methods):\n",
    "        # Calculate similarity matrix\n",
    "        n_files = len(embeddings_list)\n",
    "        similarity_matrix = np.zeros((n_files, n_files))\n",
    "        \n",
    "        for i in range(n_files):\n",
    "            for j in range(n_files):\n",
    "                if i == j:\n",
    "                    similarity_matrix[i, j] = 1.0  # Perfect similarity with itself\n",
    "                else:\n",
    "                    try:\n",
    "                        sim = compare_embeddings(\n",
    "                            embeddings_list[i], \n",
    "                            embeddings_list[j], \n",
    "                            method=method\n",
    "                        )\n",
    "                        similarity_matrix[i, j] = sim\n",
    "                    except:\n",
    "                        similarity_matrix[i, j] = 0.0\n",
    "        \n",
    "        # Plot heatmap\n",
    "        im = axes[method_idx].imshow(similarity_matrix, cmap='viridis', vmin=0, vmax=1)\n",
    "        axes[method_idx].set_title(f'{method.title()} Similarity')\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(n_files):\n",
    "            for j in range(n_files):\n",
    "                text = axes[method_idx].text(j, i, f'{similarity_matrix[i, j]:.2f}',\n",
    "                                           ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
    "        \n",
    "        # Set labels\n",
    "        short_names = [f[:10] + '...' if len(f) > 10 else f for f in filenames]\n",
    "        axes[method_idx].set_xticks(range(n_files))\n",
    "        axes[method_idx].set_yticks(range(n_files))\n",
    "        axes[method_idx].set_xticklabels(short_names, rotation=45, ha='right')\n",
    "        axes[method_idx].set_yticklabels(short_names)\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=axes[method_idx], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find most and least similar pairs\n",
    "    print(\"\\nüîç Similarity Analysis (using cosine similarity):\")\n",
    "    cosine_similarities = []\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        for j in range(i+1, len(filenames)):\n",
    "            sim = compare_embeddings(embeddings_list[i], embeddings_list[j], method='cosine')\n",
    "            cosine_similarities.append((filenames[i], filenames[j], sim))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    cosine_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    print(\"\\nüìä Most similar pairs:\")\n",
    "    for i, (file1, file2, sim) in enumerate(cosine_similarities[:3]):\n",
    "        print(f\"   {i+1}. {file1} ‚Üî {file2}: {sim:.3f}\")\n",
    "    \n",
    "    print(\"\\nüìä Least similar pairs:\")\n",
    "    for i, (file1, file2, sim) in enumerate(cosine_similarities[-3:]):\n",
    "        print(f\"   {i+1}. {file1} ‚Üî {file2}: {sim:.3f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Need at least 2 audio files for similarity comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similarity search function\n",
    "def find_similar_audio(query_embedding, database_embeddings, top_k=3, method='cosine'):\n",
    "    \"\"\"\n",
    "    Find the most similar audio files to a query.\n",
    "    \n",
    "    Args:\n",
    "        query_embedding: Embedding of the query audio\n",
    "        database_embeddings: Dict of {filename: embedding} for database\n",
    "        top_k: Number of similar files to return\n",
    "        method: Similarity method to use\n",
    "    \n",
    "    Returns:\n",
    "        List of (filename, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    \n",
    "    for filename, embedding in database_embeddings.items():\n",
    "        try:\n",
    "            sim = compare_embeddings(query_embedding, embedding, method=method)\n",
    "            similarities.append((filename, sim))\n",
    "        except:\n",
    "            similarities.append((filename, 0.0))\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Demonstrate similarity search\n",
    "if len(openl3_embeddings) > 1:\n",
    "    print(\"üîç Demonstrating similarity search...\")\n",
    "    \n",
    "    # Use the first file as query\n",
    "    query_filename = list(openl3_embeddings.keys())[0]\n",
    "    query_embedding = openl3_embeddings[query_filename]\n",
    "    \n",
    "    # Remove query from database for fair comparison\n",
    "    database = {k: v for k, v in openl3_embeddings.items() if k != query_filename}\n",
    "    \n",
    "    # Find similar files\n",
    "    similar_files = find_similar_audio(query_embedding, database, top_k=len(database))\n",
    "    \n",
    "    print(f\"\\nüéµ Query: {query_filename}\")\n",
    "    print(\"üìä Most similar files:\")\n",
    "    \n",
    "    for i, (filename, similarity) in enumerate(similar_files):\n",
    "        print(f\"   {i+1}. {filename}: {similarity:.3f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Similarity search complete!\")\n",
    "    print(\"üí° This is the foundation for building a music similarity search engine!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Need multiple audio files for similarity search demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a7753",
   "metadata": {},
   "source": [
    "## 10. Batch Processing Multiple Files\n",
    "\n",
    "Let's demonstrate how to efficiently process multiple audio files and build a database of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f74f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate batch processing with all available audio files\n",
    "print(\"üîÑ Demonstrating batch processing...\")\n",
    "\n",
    "# Get all audio files in the data directory\n",
    "all_audio_files = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in audio_extensions):\n",
    "            all_audio_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"üìÅ Found {len(all_audio_files)} audio files for batch processing\")\n",
    "\n",
    "if len(all_audio_files) > 0:\n",
    "    # Initialize extractor\n",
    "    batch_extractor = AudioEmbeddingExtractor(model_name='spectrogram')  # Use fast model for demo\n",
    "    \n",
    "    # Process all files\n",
    "    print(\"\\nüöÄ Starting batch extraction...\")\n",
    "    batch_embeddings = batch_extractor.extract_embeddings_batch(all_audio_files)\n",
    "    \n",
    "    # Analysis\n",
    "    successful = sum(1 for v in batch_embeddings.values() if v is not None)\n",
    "    failed = len(batch_embeddings) - successful\n",
    "    \n",
    "    print(f\"\\nüìä Batch Processing Results:\")\n",
    "    print(f\"   ‚úÖ Successful: {successful}\")\n",
    "    print(f\"   ‚ùå Failed: {failed}\")\n",
    "    print(f\"   üìà Success rate: {successful/len(batch_embeddings)*100:.1f}%\")\n",
    "    \n",
    "    # Create embeddings database\n",
    "    embeddings_database = {\n",
    "        'metadata': {\n",
    "            'created_date': pd.Timestamp.now().isoformat(),\n",
    "            'model': 'spectrogram',\n",
    "            'total_files': len(all_audio_files),\n",
    "            'successful_extractions': successful,\n",
    "            'failed_extractions': failed\n",
    "        },\n",
    "        'embeddings': {}\n",
    "    }\n",
    "    \n",
    "    for file_path, embedding in batch_embeddings.items():\n",
    "        if embedding is not None:\n",
    "            filename = os.path.basename(file_path)\n",
    "            embeddings_database['embeddings'][filename] = {\n",
    "                'file_path': file_path,\n",
    "                'embedding': embedding,\n",
    "                'stats': {\n",
    "                    'shape': embedding.shape,\n",
    "                    'mean': float(embedding.mean()),\n",
    "                    'std': float(embedding.std()),\n",
    "                    'norm': float(np.linalg.norm(embedding))\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    # Save database\n",
    "    database_path = os.path.join(embeddings_dir, 'embeddings_database.pkl')\n",
    "    save_embeddings(\n",
    "        np.array(list(batch_embeddings.values())),  # Dummy array for the function\n",
    "        database_path, \n",
    "        embeddings_database, \n",
    "        format='pickle'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüíæ Saved embeddings database to: {database_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audio files found for batch processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary report\n",
    "print(\"üìã Creating Summary Report...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report = {\n",
    "    'Project': 'Music Embeddings Extraction',\n",
    "    'Author': 'Sergie Code',\n",
    "    'Date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Audio Files Processed': len(audio_data),\n",
    "    'Embedding Models Used': [],\n",
    "    'Total Embeddings Generated': 0,\n",
    "    'Average Embedding Dimension': 0,\n",
    "    'Available Models': list(AudioEmbeddingExtractor.get_available_models().keys()),\n",
    "    'Saved Files': len(os.listdir(embeddings_dir)) if os.path.exists(embeddings_dir) else 0\n",
    "}\n",
    "\n",
    "# Count embeddings and models\n",
    "total_embeddings = 0\n",
    "total_dimensions = 0\n",
    "\n",
    "if openl3_embeddings:\n",
    "    report['Embedding Models Used'].append('OpenL3')\n",
    "    total_embeddings += len(openl3_embeddings)\n",
    "    total_dimensions += list(openl3_embeddings.values())[0].shape[0]\n",
    "\n",
    "if audioclip_embeddings:\n",
    "    report['Embedding Models Used'].append('AudioCLIP')\n",
    "    total_embeddings += len(audioclip_embeddings)\n",
    "    total_dimensions += list(audioclip_embeddings.values())[0].shape[0]\n",
    "\n",
    "report['Total Embeddings Generated'] = total_embeddings\n",
    "report['Average Embedding Dimension'] = total_dimensions // len(report['Embedding Models Used']) if report['Embedding Models Used'] else 0\n",
    "\n",
    "# Print report\n",
    "print(\"\\nüéµ MUSIC EMBEDDINGS EXTRACTION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in report.items():\n",
    "    if isinstance(value, list):\n",
    "        print(f\"{key:<25}: {', '.join(value) if value else 'None'}\")\n",
    "    else:\n",
    "        print(f\"{key:<25}: {value}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. üîç Build a vector search system using FAISS or Chroma\")\n",
    "print(\"2. üåê Create a REST API for embedding extraction\")\n",
    "print(\"3. üìä Develop a web interface for music analysis\")\n",
    "print(\"4. üõ°Ô∏è Implement copyright detection algorithms\")\n",
    "print(\"5. ü§ñ Train custom models for specific music genres\")\n",
    "\n",
    "print(\"\\n‚ú® PROJECT COMPLETE!\")\n",
    "print(\"This foundation is ready for building advanced music AI tools.\")\n",
    "print(\"\\nüéì Created by Sergie Code - AI Tools for Musicians\")\n",
    "print(\"üí° Subscribe to the YouTube channel for more AI tutorials!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae69ecc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully completed the **Music Embeddings Extraction** demo! Here's what you've accomplished:\n",
    "\n",
    "### ‚úÖ What You've Built\n",
    "\n",
    "1. **üéµ Audio Processing Pipeline** - Load, preprocess, and analyze audio files\n",
    "2. **ü§ñ Embedding Extraction** - Extract high-quality embeddings using OpenL3 and AudioCLIP\n",
    "3. **üíæ Data Management** - Save and load embeddings efficiently\n",
    "4. **üìä Visualization Tools** - Visualize embeddings in 2D space\n",
    "5. **üîç Similarity Search** - Find similar audio files based on embeddings\n",
    "6. **‚ö° Batch Processing** - Process multiple files efficiently\n",
    "\n",
    "### üöÄ Next Steps for Your Music AI Journey\n",
    "\n",
    "This project provides the foundation for building:\n",
    "\n",
    "- **üéØ Music Recommendation Systems**\n",
    "- **üõ°Ô∏è Copyright Detection Tools**\n",
    "- **üì± Music Analysis Apps**\n",
    "- **üîä Audio Search Engines**\n",
    "- **üéº Composition Analysis Tools**\n",
    "\n",
    "### üìö Learning Resources\n",
    "\n",
    "**By Sergie Code - Software Engineer & AI Educator**\n",
    "\n",
    "- üé• **YouTube Channel**: More AI tutorials for musicians\n",
    "- üíª **GitHub**: Find more open-source AI tools\n",
    "- üåê **Community**: Join the discussion on AI in music\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Remember\n",
    "\n",
    "This is just the beginning! The embeddings you've extracted can power sophisticated music analysis and discovery applications. Keep experimenting and building amazing tools for musicians!\n",
    "\n",
    "**Happy coding and music making! üéµü§ñ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
